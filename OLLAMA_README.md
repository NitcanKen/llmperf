# Ollama Benchmark - ç°¡åŒ–ç‰ˆä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

é€™å€‹è…³æœ¬å®Œå…¨éµå¾ª `run_bench_vllm.sh` çš„æ¨¡å¼ï¼š
1. é‹è¡Œ benchmark æ¸¬è©¦
2. ä½¿ç”¨ `collect_llmperf_table.py` ç”Ÿæˆ CSV è¡¨æ ¼

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. ç¢ºä¿ Ollama é‹è¡Œä¸­
```bash
ollama serve
```

### 2. æ‹‰å–è¦æ¸¬è©¦çš„æ¨¡å‹
```bash
ollama pull qwen3-next:80b
ollama pull deepseek-r1:70b
ollama pull deepseek-r1:32b
ollama pull deepseek-r1:14b
ollama pull deepseek-r1:8b
```

### 3. é‹è¡Œ benchmark
```bash
./run_bench_ollama.sh
```

## ğŸ“Š è¼¸å‡ºçµæœ

æ¯å€‹æ¨¡å‹æœƒç”Ÿæˆç¨ç«‹çš„ç›®éŒ„å’Œ CSVï¼š

```
results_ollama_qwen3-next_80b/
â”œâ”€â”€ concurrency_1/
â”‚   â”œâ”€â”€ qwen3-next_80b_100_1024_summary.json
â”‚   â””â”€â”€ qwen3-next_80b_100_1024_individual_responses.json
â”œâ”€â”€ concurrency_2/
â”œâ”€â”€ ...
â””â”€â”€ benchmark_table.csv  â† ä¸»è¦çµæœè¡¨æ ¼

results_ollama_deepseek-r1_70b/
â””â”€â”€ benchmark_table.csv

results_ollama_deepseek-r1_32b/
â””â”€â”€ benchmark_table.csv

...
```

## ğŸ“ˆ CSV è¡¨æ ¼åŒ…å«çš„æŒ‡æ¨™

èˆ‡ vLLM benchmark å®Œå…¨ç›¸åŒçš„æ ¼å¼ï¼š

- **NUMBER OF CONCURRENT**: ä½µç™¼æ•¸
- **INPUT LENGTH**: è¼¸å…¥ token æ•¸
- **OUTPUT LENGTH**: è¼¸å‡º token æ•¸
- **INITIAL (S)**: TTFT (Time to First Token) å¹³å‡å€¼
- **TOKEN GENERATION SPEED**: æ¯å€‹ token çš„ç”Ÿæˆæ™‚é–“ (ç§’/token)
- **TOKENS/S/USER (OUT)**: æ¯å€‹è«‹æ±‚çš„è¼¸å‡ºååé‡
- **TOKENS/S/USER (OUT + INPUT)**: æ¯å€‹è«‹æ±‚çš„ç¸½ååé‡
- **THROUGHPUT/S**: ç³»çµ±æ•´é«”ååé‡ (tokens/ç§’)
- **TTFT P50/P95**: TTFT çš„ 50th/95th ç™¾åˆ†ä½æ•¸
- **E2E MEAN/P50/P95**: End-to-End å»¶é²çµ±è¨ˆ
- **ERROR RATE**: éŒ¯èª¤ç‡

## ğŸ”§ é—œéµä¿®å¾©

è…³æœ¬åŒ…å«äº†é‡å° Ollama çš„é‡è¦ä¿®å¾©ï¼š

```bash
--additional-sampling-params '{"max_tokens":1024,"options":{"num_predict":1024,"num_ctx":4096,"temperature":0.7,"top_p":0.9}}'
```

**ç‚ºä»€éº¼éœ€è¦é€™äº›åƒæ•¸ï¼Ÿ**
- `max_tokens`: OpenAI API æ¨™æº–åƒæ•¸
- `options.num_predict`: Ollama åŸç”Ÿåƒæ•¸ï¼Œæ§åˆ¶ç”Ÿæˆ token æ•¸
- `options.num_ctx`: Context window å¤§å°ï¼Œç¢ºä¿æœ‰è¶³å¤ ç©ºé–“ç”Ÿæˆ
- å…©è€…éƒ½è¨­ç½®ç¢ºä¿å…¼å®¹æ€§

## ğŸ¯ èˆ‡ vLLM è…³æœ¬çš„å°æ¯”

### run_bench_vllm.sh
```bash
for c in "${concurrencies[@]}"; do
  OUT_DIR="results_Mixtral_176B/concurrency_${c}"
  python token_benchmark_ray.py ...
done
# ç„¶å¾Œæ‰‹å‹•é‹è¡Œ: python collect_llmperf_table.py --base-dir results_Mixtral_176B
```

### run_bench_ollama.sh (æ–°)
```bash
for model in "${models[@]}"; do
  for c in "${concurrencies[@]}"; do
    OUT_DIR="results_ollama_${model}/concurrency_${c}"
    python token_benchmark_ray.py ...
  done
  # è‡ªå‹•ç”Ÿæˆ CSV
  python collect_llmperf_table.py --base-dir "results_ollama_${model}"
done
```

**æ”¹é€²**ï¼š
- âœ… æ”¯æŒå¤šå€‹æ¨¡å‹
- âœ… è‡ªå‹•èª¿ç”¨ `collect_llmperf_table.py`
- âœ… æ¯å€‹æ¨¡å‹ç¨ç«‹çš„çµæœç›®éŒ„å’Œ CSV

## ğŸ§ª æ¸¬è©¦å–®å€‹æ¨¡å‹

å¦‚æœåªæƒ³æ¸¬è©¦ä¸€å€‹æ¨¡å‹ï¼Œç·¨è¼¯è…³æœ¬ç¬¬ 4-10 è¡Œï¼š

```bash
models=(
  "deepseek-r1:8b"  # åªæ¸¬è©¦é€™ä¸€å€‹
)
```

## ğŸ“ æŸ¥çœ‹çµæœ

```bash
# æŸ¥çœ‹æŸå€‹æ¨¡å‹çš„çµæœ
cat results_ollama_deepseek-r1_8b/benchmark_table.csv

# æˆ–ç”¨ column æ ¼å¼åŒ–é¡¯ç¤º
column -t -s, results_ollama_deepseek-r1_8b/benchmark_table.csv | less -S
```

## â±ï¸ é ä¼°æ™‚é–“

- **deepseek-r1:8b**: ~20-40 åˆ†é˜
- **deepseek-r1:14b**: ~30-60 åˆ†é˜
- **deepseek-r1:32b**: ~1-2 å°æ™‚
- **deepseek-r1:70b**: ~2-3 å°æ™‚
- **qwen3-next:80b**: ~2-3 å°æ™‚

**ç¸½è¨ˆ**: ç´„ 6-10 å°æ™‚ï¼ˆ5 å€‹æ¨¡å‹ Ã— 7 å€‹ä½µç™¼ç´šåˆ¥ï¼‰

## ğŸ’¡ æç¤º

1. **ä½¿ç”¨ tmux/screen** é¿å…æ–·ç·šï¼š
   ```bash
   tmux new -s ollama_bench
   ./run_bench_ollama.sh
   # Ctrl+B, D åˆ†é›¢
   ```

2. **ç›£æ§é€²åº¦**ï¼š
   ```bash
   # æŸ¥çœ‹æœ€æ–°ç”Ÿæˆçš„æ–‡ä»¶
   find results_ollama_* -name "*.json" -mmin -5
   ```

3. **åªæ¸¬è©¦å°æ¨¡å‹å…ˆé©—è­‰**ï¼š
   ```bash
   models=("deepseek-r1:8b")  # ä¿®æ”¹è…³æœ¬
   concurrencies=("1" "4")     # åªæ¸¬è©¦ 2 å€‹ä½µç™¼ç´šåˆ¥
   ```

å°±æ˜¯é€™éº¼ç°¡å–®ï¼ğŸ‰
